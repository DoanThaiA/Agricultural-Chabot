
import base64
import json
import uuid
from typing import TypedDict, Annotated, List, Optional, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage
import operator
from dotenv import load_dotenv
from langchain_cohere import ChatCohere
from agents.predict_image import predict_image_agent
from agents.text_analyzer import text_analyzer_agent
from langgraph.checkpoint.memory import InMemorySaver
import os
from langchain_huggingface import HuggingFaceEmbeddings
from agents.vector_store import vector_store

load_dotenv()
def encode_image(image_path: str) -> str:
    """Encode image to base64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


class AgricultureState(TypedDict):
    """State definition for the agriculture chatbot"""
    messages: Annotated[List, operator.add]
    user_query: str
    query_type: str
    condensed_query: str
    image_data: Optional[str]
    disease_info: Optional[dict]
    context: dict


def condense_conversation_history(state: AgricultureState) -> AgricultureState:
    """
    N√©n l·ªãch s·ª≠ h·ªôi tho·∫°i V√Ä x·ª≠ l√Ω th√¥ng tin b·ªï sung.
    """
    messages = state.get("messages", [])
    if not messages:
        return {"condensed_query": "", "messages": [AIMessage(content="L·ªói: Kh√¥ng c√≥ tin nh·∫Øn.")]}

    user_query = messages[-1].content
    chat_history = messages[-6:-1]

    if not chat_history:
        return {
            **state,
            "condensed_query": user_query,
            "user_query": user_query
        }

    llm = ChatCohere(model="command-r-plus-08-2024", temperature=0)
    history_str = "\n".join([f"{msg.type}: {msg.content}" for msg in chat_history])

    prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI c√≥ nhi·ªám v·ª• vi·∫øt l·∫°i c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
D·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i v√† c√¢u h·ªèi m·ªõi, h√£y l√†m theo c√°c quy t·∫Øc sau:

1.  **Ti·∫øp n·ªëi (Follow-up):** N·∫øu c√¢u h·ªèi m·ªõi l√† c√¢u h·ªèi ti·∫øp n·ªëi (v√≠ d·ª•: "ch·ªØa th·∫ø n√†o?", "nguy√™n nh√¢n?"), 
    h√£y vi·∫øt l·∫°i n√≥ th√†nh m·ªôt c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß ng·ªØ c·∫£nh t·ª´ l·ªãch s·ª≠.
    *V√≠ d·ª• L·ªãch s·ª≠: "B·ªánh X"; C√¢u m·ªõi: "C√°ch ch·ªØa?"; K·∫øt qu·∫£: "C√°ch ch·ªØa b·ªánh X?"*

2.  **B·ªï sung (Correction/Addition):** N·∫øu c√¢u h·ªèi m·ªõi l√† m·ªôt th√¥ng tin **b·ªï sung** ho·∫∑c **s·ª≠a l·ªói** cho c√¢u h·ªèi ngay tr∆∞·ªõc ƒë√≥ 
    (v√≠ d·ª•: ng∆∞·ªùi d√πng m√¥ t·∫£ tri·ªáu ch·ª©ng, sau ƒë√≥ n√≥i t√™n c√¢y tr·ªìng), 
    h√£y **k·∫øt h·ª£p** l·ªãch s·ª≠ g·∫ßn nh·∫•t v√† c√¢u m·ªõi th√†nh m·ªôt c√¢u h·ªèi ho√†n ch·ªânh.
    *V√≠ d·ª• L·ªãch s·ª≠: "...v·∫øt h√¨nh thoi"; C√¢u m·ªõi: "tr√™n c√¢y l√∫a"; K·∫øt qu·∫£: "c√¢y l√∫a c√≥ v·∫øt h√¨nh thoi l√† b·ªánh g√¨?"*
3. **Thay ƒë·ªïi** N·∫øu ng∆∞·ªùi d√πng h·ªèi m·ªôt c√¢u h·ªèi ho√†n to√†n m·ªõi kh√¥ng li√™n quan g√¨ ƒë·∫øn tin nh·∫Øn tr∆∞·ªõc ƒë√≥ h√£y g√¨ nguy√™n c√¢u h·ªèi
    c·ªßa ng∆∞·ªùi d√πng.V√≠ d·ª• khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ lo·∫°i c√¢y tr·ªìng kh√°c, ho·∫∑c v·∫•n ƒë·ªÉ kh√°c kh√¥ng li√™n quan ƒë·∫øn qu√° kh·ª©.

L·ªãch s·ª≠:
{history_str}

C√¢u m·ªõi: {user_query}

K·∫øt qu·∫£ (vi·∫øt l·∫°i ho·∫∑c k·∫øt h·ª£p):"""

    response = llm.invoke(prompt)
    condensed_query = response.content.strip()

    print(f"[Condenser]: ƒê√£ n√©n th√†nh: {condensed_query}")

    return {
        **state,
        "condensed_query": condensed_query,
        "user_query": user_query
    }
def classify_input(state: AgricultureState) -> AgricultureState:
    """Classify the type of user query"""
    image_data = state.get("image_data")
    if image_data:
        return {
            **state,
            "query_type": "image_disease"
        }
    llm = ChatCohere(model="command-r-plus-08-2024", temperature=0)
    classification_prompt = f"""Truy v·∫•n: {state['condensed_query']}
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc n·ªôi dung ng∆∞·ªùi d√πng nh·∫≠p v√†o v√† ph√¢n lo·∫°i n√≥ th√†nh ƒë√∫ng m·ªôt trong ba lo·∫°i sau ƒë√¢y:
    text_disease: khi ng∆∞·ªùi d√πng m√¥ t·∫£ b·∫±ng ch·ªØ c√°c tri·ªáu ch·ª©ng, d·∫•u hi·ªáu ho·∫∑c t√¨nh tr·∫°ng b·ªánh c·ªßa c√¢y tr·ªìng v√† mu·ªën bi·∫øt ƒë√≥ l√† b·ªánh g√¨, nguy√™n nh√¢n ho·∫∑c c√°ch ch·ªØa. V√≠ d·ª• nh∆∞ ‚ÄúL√° l√∫a b·ªã ƒë·ªëm n√¢u, c√¢y c√≤i c·ªçc l√† b·ªánh g√¨‚Äù ho·∫∑c ‚ÄúC√¢y c√† chua b·ªã v√†ng l√°, h√©o d·∫ßn l√† sao‚Äù.
    normal_qa: khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ ki·∫øn th·ª©c n√¥ng nghi·ªáp n√≥i chung, kh√¥ng m√¥ t·∫£ b·ªánh c·ª• th·ªÉ. Bao g·ªìm c√°c c√¢u h·ªèi v·ªÅ k·ªπ thu·∫≠t tr·ªìng, chƒÉm s√≥c, b√≥n ph√¢n, th·ªùi v·ª•, gi·ªëng c√¢y, c√¥n tr√πng, ƒë·∫•t ƒëai, ho·∫∑c dinh d∆∞·ª°ng. V√≠ d·ª• nh∆∞ ‚ÄúC√°ch b√≥n ph√¢n cho c√¢y cam‚Äù, ‚Äúƒê·∫•t tr·ªìng rau n√™n c√≥ ƒë·ªô pH bao nhi√™u‚Äù ho·∫∑c ‚ÄúGi·ªëng l√∫a n√†o nƒÉng su·∫•t cao‚Äù.
    chitchat: khi ng∆∞·ªùi d√πng ch√†o h·ªèi, c·∫£m ∆°n, n√≥i chuy·ªán phi·∫øm ho·∫∑c ƒë·∫∑t c√°c c√¢u h·ªèi kh√¥ng li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ki·∫øn th·ª©c n√¥ng nghi·ªáp. Nh√≥m n√†y c≈©ng bao g·ªìm nh·ªØng c√¢u h·ªèi v·ªÅ th·ªùi ti·∫øt, gi√° c·∫£, tin t·ª©c ho·∫∑c b·∫•t k·ª≥ th√¥ng tin n√†o c·∫ßn t√¨m ki·∫øm tr√™n m·∫°ng. V√≠ d·ª• nh∆∞ ‚ÄúCh√†o b·∫°n‚Äù, ‚ÄúC·∫£m ∆°n nh√©‚Äù, ‚ÄúTh·ªùi ti·∫øt ·ªü H√† N·ªôi h√¥m nay th·∫ø n√†o‚Äù ho·∫∑c ‚ÄúGi√° ph√¢n DAP h√¥m nay l√† bao nhi√™u‚Äù.
    Ch·ªâ tr·∫£ v·ªÅ **m·ªôt trong ba nh√£n duy nh·∫•t** sau ƒë√¢y, kh√¥ng gi·∫£i th√≠ch th√™m:
    - text_disease  
    - normal_qa  
    - chitchat"""
    response = llm.invoke([HumanMessage(content=classification_prompt)])
    query_type = response.content.strip().lower()
    valid_types = ["text_disease", "normal_qa", "chitchat"]
    if query_type not in valid_types:
        query_type = "chitchat"
    return {
        **state,
        "query_type": query_type}
def chitchat(state: AgricultureState) -> AgricultureState:
    """T·∫°o ph·∫£n h·ªìi nhanh cho c√°c c√¢u ch√†o h·ªèi, c·∫£m ∆°n."""
    # B·∫°n c√≥ th·ªÉ d√πng LLM n·∫øu mu·ªën c√¢u tr·∫£ l·ªùi ƒëa d·∫°ng
    prompt = f"Ng∆∞·ªùi d√πng: {state['user_query']}. B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn."
    try:
        # G·ªçi model ho·∫∑c agent
        response = text_analyzer_agent.invoke({"messages": [HumanMessage(content=prompt)]})

        # X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ
        if isinstance(response, dict):
            # Tr∆∞·ªùng h·ª£p model tr·∫£ v·ªÅ d·∫°ng dict
            if "output" in response:
                content = response["output"]
            elif "messages" in response and response["messages"]:
                content = response["messages"][-1].content
            else:
                content = str(response)
        elif hasattr(response, "content"):
            # Tr∆∞·ªùng h·ª£p l√† AIMessage
            content = response.content
        else:
            # N·∫øu ch·ªâ l√† chu·ªói ho·∫∑c object kh√°c
            content = str(response)

    except Exception as e:
        print(f"[Chitchat Error]: {e}")
        content = "Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë. B·∫°n th·ª≠ l·∫°i sau nh√© üå±"

    # Tr·∫£ v·ªÅ ƒë√∫ng d·∫°ng dict m√† LangGraph y√™u c·∫ßu
    return {
        "messages": [AIMessage(content=content)]
    }


def analyze_image(state: AgricultureState) -> AgricultureState:
    """Ph√¢n t√≠ch ·∫£nh (ƒê√É S·ª¨A: L∆∞u file t·∫°m, g·ª≠i path cho agent)."""

    image_data = state.get('image_data')  # L·∫•y d·ªØ li·ªáu base64
    temp_filename = None  # Kh·ªüi t·∫°o ƒë·ªÉ d√πng trong finally

    if not image_data:
        return {
            "disease_info": {"error": "No image provided"},
            "messages": [AIMessage(content="Kh√¥ng c√≥ ·∫£nh n√†o ƒë∆∞·ª£c g·ª≠i l√™n.")]
        }

    try:
        # 1. Decode base64 th√†nh bytes
        image_bytes = base64.b64decode(image_data)

        # 2. T·∫°o th∆∞ m·ª•c t·∫°m n·∫øu ch∆∞a c√≥
        temp_dir = "temp_images"
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)

        # 3. T·∫°o t√™n file t·∫°m ng·∫´u nhi√™n
        temp_filename = os.path.join(temp_dir, f"{uuid.uuid4()}.jpg")

        # 4. L∆∞u ·∫£nh v√†o file t·∫°m
        with open(temp_filename, "wb") as f:
            f.write(image_bytes)
        print(f"·∫¢nh t·∫°m ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {temp_filename}")

        # 5. Chu·∫©n b·ªã input ƒë∆°n gi·∫£n cho Agent (ch·ª©a ƒë∆∞·ªùng d·∫´n file)
        agent_input_prompt = f"""H√£y ph√¢n t√≠ch h√¨nh ·∫£nh c√¢y tr·ªìng t·∫°i ƒë∆∞·ªùng d·∫´n sau: {temp_filename}

        S·ª≠ d·ª•ng tool 'predict' ƒë·ªÉ x√°c ƒë·ªãnh b·ªánh v√† ƒë·ªô tin c·∫≠y.
        Ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON t·ª´ tool. Kh√¥ng th√™m b·∫•t k·ª≥ l·ªùi gi·∫£i th√≠ch n√†o.
        V√≠ d·ª• JSON mong mu·ªën:
        {{
          "label": "...", 
          "confidence": 0.xx 
        }}
        """
        agent_input_message = HumanMessage(content=agent_input_prompt)

        # 6. G·ªçi agent V·ªöI ƒê∆Ø·ªúNG D·∫™N FILE
        response = predict_image_agent.invoke({"messages": [agent_input_message]})

        # 7. X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ agent
        agent_output = response.get('output') or response['messages'][-1].content

        try:
            # Agent c√≥ th·ªÉ tr·∫£ v·ªÅ JSON tr·ª±c ti·∫øp ho·∫∑c trong ```json ... ```
            if "```json" in agent_output:
                agent_output = agent_output.split("```json")[1].split("```")[0]

            # Parse k·∫øt qu·∫£ JSON t·ª´ tool (do agent tr·∫£ v·ªÅ)
            tool_result = json.loads(agent_output.strip())

            # Ki·ªÉm tra xem tool c√≥ tr·∫£ v·ªÅ l·ªói kh√¥ng
            if "error" in tool_result:
                raise ValueError(tool_result["error"])

            # Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng cho ph√π h·ª£p v·ªõi AgricultureState
            disease_info = {
                # C·ªë g·∫Øng t√°ch t√™n c√¢y kh·ªèi t√™n b·ªánh n·∫øu c√≥
                "plant_type": tool_result.get("label", "Unknown").split(' ')[0],
                "disease_detected": tool_result.get("label", "Analysis inconclusive"),
                # Chuy·ªÉn ƒë·ªïi confidence (0.x) th√†nh chu·ªói %
                "confidence": f"{tool_result.get('confidence', 0) * 100:.1f}%"
            }

        except Exception as parse_error:
            print(f"L·ªói parse JSON t·ª´ agent output: {parse_error}\nRaw output: {agent_output}")
            disease_info = {"plant_type": "Unknown", "disease_detected": "Analysis inconclusive", "confidence": None}

    except Exception as e:
        print(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω ·∫£nh ho·∫∑c g·ªçi agent: {e}")
        disease_info = {"plant_type": "Unknown", "disease_detected": "Error processing image", "confidence": None}

    finally:
        # X√≥a file t·∫°m sau khi d√πng xong
        if temp_filename and os.path.exists(temp_filename):
            try:
                os.remove(temp_filename)
                print(f"ƒê√£ x√≥a file t·∫°m: {temp_filename}")
            except Exception as delete_error:
                print(f"L·ªói khi x√≥a file t·∫°m {temp_filename}: {delete_error}")

    return {
        **state,
        "disease_info": disease_info,
    }


def request_more_info(state: AgricultureState) -> AgricultureState:
    """T·∫°o m·ªôt tin nh·∫Øn y√™u c·∫ßu ng∆∞·ªùi d√πng g·ª≠i l·∫°i ·∫£nh ho·∫∑c tin nh·∫Øn cung c·∫•p th√™m th√¥ng tin"""
    confidence_str = state['disease_info'].get('confidence', '0%')
    disease_detected = state['disease_info'].get('disease_detected', 'kh√¥ng x√°c ƒë·ªãnh')
    message_content = f"""K·∫øt qu·∫£ ph√¢n t√≠ch ·∫£nh c√≥ ƒë·ªô tin c·∫≠y h∆°i th·∫•p ({confidence_str} cho b·ªánh {disease_detected}).
    ƒê·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c h∆°n, b·∫°n vui l√≤ng:
    1.  **G·ª≠i m·ªôt b·ª©c ·∫£nh kh√°c** (r√µ n√©t h∆°n, ƒë·ªß s√°ng, ch·ª•p g·∫ßn khu v·ª±c b·ªã b·ªánh).
    2.  **Ho·∫∑c m√¥ t·∫£ th√™m** v·ªÅ c√°c tri·ªáu ch·ª©ng b·∫°n quan s√°t ƒë∆∞·ª£c"""
    return {
        "messages": [AIMessage(content=message_content)]
    }


def retrieve_knowledge(state: AgricultureState) -> AgricultureState:
    global vector_store  # ƒê·∫£m b·∫£o d√πng ƒë√∫ng
    if not vector_store:
        print("L·ªói: vector_store kh√¥ng ƒë∆∞·ª£c load, b·ªè qua RAG.")
        return {"context": {"retrieved_docs": [], "sources": [], "has_good_content": False}}
    if state.get('disease_info'):
        search_query = f"{state['disease_info'].get('disease_detected', '')} {state['condensed_query']}"
    else:
        search_query = state['condensed_query']

    docs = vector_store.similarity_search_with_relevance_scores(search_query, k=3)

    # --- Th√™m Log ƒë·ªÉ ki·ªÉm tra score ---
    print(f"\n--- K·∫æT QU·∫¢ RAG (Query: {search_query}) ---")
    print(docs)
    # --- K·∫øt th√∫c Log ---

    good_docs = [doc for doc, score in docs if score > 0.55]
    has_good_context = len(good_docs) > 0
    retrieved_docs_list = []
    sources_list = []
    if has_good_context:
        # N·∫øu t√¨m th·∫•y, ch·ªâ l·∫•y t√†i li·ªáu ƒë·∫ßu ti√™n (t·ªët nh·∫•t)
        retrieved_docs_list = [good_docs[0].page_content]
        sources_list = [good_docs[0].metadata.get("source", "Unknown")]
    context = {
        "retrieved_docs": retrieved_docs_list,
        "sources": sources_list,
        "has_good_context": has_good_context
    }

    print(f"--- Has Good Context: {context['has_good_context']} ---")  # Th√™m Log

    return {
        **state,
        "context": context}


def request_clarification(state: AgricultureState) -> AgricultureState:
    """
    T·∫°o tin nh·∫Øn khi RAG kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan.
    Y√™u c·∫ßu ng∆∞·ªùi d√πng m√¥ t·∫£ l·∫°i.
    """
    message_content = f"""R·∫•t ti·∫øc, t√¥i kh√¥ng th·ªÉ t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c v·ªÅ "{state['condensed_query']}" trong c∆° s·ªü ki·∫øn th·ª©c c·ªßa m√¨nh.

B·∫°n c√≥ th·ªÉ vui l√≤ng:
1.  **M√¥ t·∫£ l·∫°i c√°c tri·ªáu ch·ª©ng** b·∫±ng t·ª´ ng·ªØ kh√°c?
2.  **Ki·ªÉm tra l·∫°i t√™n** c·ªßa lo·∫°i b·ªánh/c√¢y b·∫°n ƒëang h·ªèi?

ƒêi·ªÅu n√†y s·∫Ω gi√∫p t√¥i t√¨m ki·∫øm ch√≠nh x√°c h∆°n."""

    return {
        "messages": [AIMessage(content=message_content)]
    }


async def generate_disease_diagnosis(state: AgricultureState) -> AgricultureState:
    """Generate detailed disease diagnosis"""
    llm = ChatCohere(model="command-r-plus-08-2024", temperature=0.3)
    context_text = "\n\n".join(state['context'].get('retrieved_docs', []))
    if state['query_type'] == "image_disease":
        disease_context = f"""
        Image Analysis Results:
        - Plant Type: {state['disease_info'].get('plant_type', 'Unknown')}
        - Disease: {state['disease_info'].get('disease_detected', 'Unknown')}
        - Confidence: {state['disease_info'].get('confidence', 'Unknown')}
        """
    else:
        disease_context = f"User's description: {state['condensed_query']}"
    diagnosis_prompt = f"""You are an agricultural consultant. Based on the following information, make a diagnosis of the plant's condition.

    {disease_context}

    Relevant Knowledge:
    {context_text}
    
    Please state clearly:
        1. **Diagnosis:** Disease name and level of confidence.
        2. **Description of symptoms:** (If available in knowledge).
        3. **Causes/Conditions of spread:** (If any).
        4. End with a word of encouragement and an offer of additional support.
        Answer in Vietnamese"""
    try:
        response = await  llm.ainvoke([HumanMessage(content=diagnosis_prompt)])
        final_response_content = response.content.strip()

    # N·∫øu kh√¥ng c√≥ n·ªôi dung (v√≠ d·ª• l·ªói)
        if not final_response_content:
            final_response_content = "Xin l·ªói, t√¥i ch∆∞a th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi l√∫c n√†y."

    except Exception as e:
        print(f"L·ªói invoke format: {e}")  # S·ª≠a t√™n l·ªói
        final_response_content = "L·ªói khi t·∫°o ph·∫£n h·ªìi cu·ªëi c√πng."


    return {
        **state,
        "messages": [AIMessage(content=final_response_content)]
    }


async def generate_normal_qa(state: AgricultureState) -> AgricultureState:
    """Generate response for normal agriculture question"""
    llm = ChatCohere(model="command-r-plus-08-2024", temperature=0.3)
    normal_prompt = f"""You are an expert agricultural advisor. Answer the following question comprehensively.
    Question: {state['condensed_query']}
    Please answer accurately and according to the user's request, do not reply to another topic by mistake. Answer in Vietnamese"""
    try:
        response = await  llm.ainvoke([HumanMessage(content=normal_prompt)])
        final_response_content = response.content.strip()

        # N·∫øu kh√¥ng c√≥ n·ªôi dung (v√≠ d·ª• l·ªói)
        if not final_response_content:
            final_response_content = "Xin l·ªói, t√¥i ch∆∞a th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi l√∫c n√†y."

    except Exception as e:
        print(f"L·ªói invoke format: {e}")  # S·ª≠a t√™n l·ªói
        final_response_content = "L·ªói khi t·∫°o ph·∫£n h·ªìi cu·ªëi c√πng."

    return {
        **state,
        "messages": [AIMessage(content=final_response_content)]
    }
def create_agriculture_graph():
    memory = InMemorySaver()
    """Create the LangGraph workflow"""
    workflow = StateGraph(AgricultureState)
    workflow.add_node("condense_history", condense_conversation_history)
    workflow.add_node("classify", classify_input)
    workflow.add_node("chitchat", chitchat)
    workflow.add_node("analyze_image", analyze_image)
    workflow.add_node("request_more_info", request_more_info)
    workflow.add_node("retrieve_knowledge", retrieve_knowledge)
    workflow.add_node("request_clarification", request_clarification)
    workflow.add_node("diagnose_disease", generate_disease_diagnosis)
    workflow.add_node("normal_qa", generate_normal_qa)
    workflow.set_entry_point("condense_history")
    workflow.add_edge("condense_history", "classify")

    def route_after_classify(state: AgricultureState) -> str:

        if state['query_type'] == "image_disease":
            return "analyze_image"
        if state['query_type'] == "chitchat":
            return "chitchat"
        else:
            return "retrieve_knowledge"

    workflow.add_conditional_edges(
        "classify",
        route_after_classify,
        {
            "analyze_image": "analyze_image",
            "retrieve_knowledge": "retrieve_knowledge",
            "chitchat": "chitchat"
        }
    )

    def check_confidence(state: AgricultureState) -> str:
        """
        Ki·ªÉm tra ƒë·ªô tin c·∫≠y t·ª´ node analyze_image.
        Ch·ªâ ƒë∆∞·ª£c g·ªçi n·∫øu query_type l√† 'image_disease'.
        """
        try:
            confidence_str = state['disease_info'].get('confidence', '0%')
            if confidence_str is None:
                # N·∫øu confidence l√† None (do l·ªói ph√¢n t√≠ch), coi nh∆∞ ƒë·ªô tin c·∫≠y th·∫•p
                print("Confidence l√† None. Y√™u c·∫ßu th√™m th√¥ng tin.")
                return "request_more_info"
            # Chuy·ªÉn ƒë·ªïi "number%" th√†nh float
            confidence_val = float(confidence_str.replace('%', '').strip())

            if confidence_val < 70:
                print(f"ƒê·ªô tin c·∫≠y th·∫•p ({confidence_val}%), y√™u c·∫ßu th√™m th√¥ng tin.")
                return "request_more_info"
            else:
                print(f"ƒê·ªô tin c·∫≠y cao ({confidence_val}%), ti·∫øp t·ª•c retrieval.")
                return "retrieve_knowledge"
        except Exception as e:
            # B·∫Øt c√°c l·ªói kh√°c (v√≠ d·ª•: kh√¥ng th·ªÉ chuy·ªÉn 'number%' th√†nh float)
            print(f"L·ªói khi ki·ªÉm tra ƒë·ªô tin c·∫≠y: {e}. Y√™u c·∫ßu th√™m th√¥ng tin.")
            return "request_more_info"

    workflow.add_conditional_edges(
        "analyze_image",
        check_confidence,
        {
            "retrieve_knowledge": "retrieve_knowledge",
            "request_more_info": "request_more_info"
        }
    )

    def route_after_retrieval(state: AgricultureState) -> str:
        if not state['context'].get('has_good_context'):
            print("RAG kh√¥ng t√¨m th·∫•y context t·ªët. Y√™u c·∫ßu l√†m r√µ.")
            return "request_clarification"
        if state['query_type'] in ["image_disease", "text_disease"]:
            return "diagnose_disease"
        else:
            return "normal_qa"

    workflow.add_conditional_edges(
        "retrieve_knowledge",
        route_after_retrieval,
        {
            "diagnose_disease": "diagnose_disease",
            "normal_qa": "normal_qa",
            "request_clarification": "request_clarification"
        }
    )

    workflow.add_edge("diagnose_disease",END)
    workflow.add_edge("normal_qa",END)
    workflow.add_edge("request_more_info", END)
    workflow.add_edge("request_clarification", END)
    workflow.add_edge("chitchat", END)

    return workflow.compile(checkpointer=memory)

app = create_agriculture_graph()